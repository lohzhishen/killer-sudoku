{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "ArR3jNDM6lVi"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import sklearn.metrics\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pathlib\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# create directories\n",
        "BASE_MODEL = pathlib.Path('Models','base_model.keras')\n",
        "MODEL = pathlib.Path('Models', 'digit_recognizer.keras')\n",
        "LABELLED = pathlib.Path('Models', 'Dataset', 'Digit Recognizer', 'Labelled')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "zra44Nqf0V-M"
      },
      "outputs": [],
      "source": [
        "# load the base model\n",
        "model = keras.models.load_model(BASE_MODEL)\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "    metrics='accuracy'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "9LQobe4SGPeh"
      },
      "outputs": [],
      "source": [
        "# verify that base model is loaded properly\n",
        "def transform(img):\n",
        "    return (255 - img).astype('float32') / 255\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "transformed_x_train = transform(x_train)\n",
        "transformed_x_test = transform(x_test)\n",
        "encoder = sklearn.preprocessing.LabelBinarizer()\n",
        "transformed_y_train = encoder.fit_transform(y_train)\n",
        "transformed_y_test = encoder.transform(y_test)\n",
        "model.evaluate(transformed_x_test, transformed_y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "mXhnd22a7Pve"
      },
      "outputs": [],
      "source": [
        "# function to scale and one hot encode response\n",
        "def transform(x, y):\n",
        "    x = tf.cast(x, tf.float32) / 255\n",
        "    x =  tf.image.resize(x, [28, 28])\n",
        "    y = tf.one_hot(y, 10, dtype=tf.uint8)\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5zWmMQD-HrM",
        "outputId": "d79e7565-f38f-4206-e04a-a603319f5c1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 422 files belonging to 10 classes.\n",
            "Using 380 files for training.\n",
            "Found 422 files belonging to 10 classes.\n",
            "Using 42 files for validation.\n"
          ]
        }
      ],
      "source": [
        "# load the datasets\n",
        "train_dataset = keras.utils.image_dataset_from_directory(\n",
        "    LABELLED,\n",
        "    label_mode='int',\n",
        "    color_mode='grayscale',\n",
        "    batch_size=32,\n",
        "    image_size=(28, 28),\n",
        "    shuffle=True,\n",
        "    seed=1,\n",
        "    validation_split=0.1,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "test_dataset = keras.utils.image_dataset_from_directory(\n",
        "    LABELLED,\n",
        "    label_mode='int',\n",
        "    color_mode='grayscale',\n",
        "    batch_size=32,\n",
        "    image_size=(28, 28),\n",
        "    shuffle=True,\n",
        "    seed=1,\n",
        "    validation_split=0.1,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "train_dataset = train_dataset.map(transform)\n",
        "test_dataset = test_dataset.map(transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyu0_BHW6vEn",
        "outputId": "04237e51-85d1-4e61-a657-7d8a6cc04d17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "12/12 [==============================] - 2s 55ms/step - loss: 0.8569 - accuracy: 0.7868 - val_loss: 0.0575 - val_accuracy: 0.9762\n",
            "Epoch 2/3\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 0.2861 - accuracy: 0.9132 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "12/12 [==============================] - 1s 40ms/step - loss: 0.2046 - accuracy: 0.9395 - val_loss: 0.0099 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a87a6a923b0>"
            ]
          },
          "execution_count": 188,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train the model\n",
        "model.fit(train_dataset, epochs=3, validation_data=test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1giO9Ax0kdUB",
        "outputId": "11e245ec-5315-453d-e866-fc314f95277f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0099 - accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.009906304068863392, 1.0]"
            ]
          },
          "execution_count": 189,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate the model\n",
        "model.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "XCH7cvjGqPwa"
      },
      "outputs": [],
      "source": [
        "# extract dataset\n",
        "images, labels = zip(*test_dataset)\n",
        "labels = np.concatenate([l.numpy() for l in labels], axis=0)\n",
        "labels = labels.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LOVseKYrgaJ",
        "outputId": "22731712-307c-4c3c-e95d-30250a88e6de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 114ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 75 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7a87a6a4b2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 108ms/step\n"
          ]
        }
      ],
      "source": [
        "# make predictions\n",
        "predictions = []\n",
        "for batch in images:\n",
        "    predictions = np.concatenate([predictions, tf.argmax(model.predict(batch), axis=1).numpy()], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkTXMsvR7B74",
        "outputId": "658f6454-a955-4bb5-e113-a5088e6e78ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         8\n",
            "           2       1.00      1.00      1.00         5\n",
            "           3       1.00      1.00      1.00         4\n",
            "           4       1.00      1.00      1.00         3\n",
            "           5       1.00      1.00      1.00         6\n",
            "           6       1.00      1.00      1.00         4\n",
            "           7       1.00      1.00      1.00         2\n",
            "           8       1.00      1.00      1.00         2\n",
            "           9       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        42\n",
            "   macro avg       1.00      1.00      1.00        42\n",
            "weighted avg       1.00      1.00      1.00        42\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# evaluate the model\n",
        "print(\n",
        "    sklearn.metrics.classification_report(\n",
        "        labels,\n",
        "        predictions,\n",
        "        target_names=[str(x) for x in range(10)]\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "ecerdFDUC1jf"
      },
      "outputs": [],
      "source": [
        "# save the model\n",
        "model.save('digit_recognizer.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "Qaz8Sfz0C49c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
