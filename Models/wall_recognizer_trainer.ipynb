{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3l_-8tvxz23_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import os\n",
        "\n",
        "MODEL = pathlib.Path('wall_recognizer.keras')\n",
        "LABELLED = pathlib.Path('Dataset', 'Wall Recognizer', 'Labelled')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wiR-Oaw0p-o"
      },
      "outputs": [],
      "source": [
        "BUFFER = 128\n",
        "\n",
        "file_paths = tf.data.Dataset.list_files(str(LABELLED/'*.png'), shuffle=False).shuffle(BUFFER, reshuffle_each_iteration=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kotssfuh1XDo"
      },
      "outputs": [],
      "source": [
        "def parse_images(file_path):\n",
        "    # extract label\n",
        "    label = tf.strings.split(file_path, os.path.sep)[-1]\n",
        "    label = tf.strings.split(label, '_')[:-1]\n",
        "    label = tf.strings.to_number(label, tf.int32)\n",
        "\n",
        "    # load image\n",
        "    image = tf.io.read_file(file_path)\n",
        "    image = tf.io.decode_png(image, channels=1)\n",
        "    image = tf.image.resize(image, [28, 28])\n",
        "    image = tf.cast(image, tf.float32) / 255\n",
        "    return image, label\n",
        "\n",
        "dataset = file_paths.map(parse_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5ENpKce4qX1"
      },
      "outputs": [],
      "source": [
        "train_size = 200\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "test_dataset = dataset.skip(train_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olRCDr1q6BLo",
        "outputId": "d92f2051-0c73-4110-c7c0-fdf49a662132"
      },
      "outputs": [],
      "source": [
        "image = iter(train_dataset).__next__()\n",
        "print(image[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "bQnrU_yf5HlG",
        "outputId": "637f837d-e285-422f-99d1-3c477d05db56"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "for i, (image, label) in zip(range(3), iter(train_dataset)):\n",
        "    label = label.numpy().astype(np.uint8).tolist()\n",
        "\n",
        "    plt.subplot(1, 3, i + 1)\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.title('_'.join([str(x) for x in label]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djm8qV5h8iBW"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.batch(256)\n",
        "test_dataset = test_dataset.batch(256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbPuuM0k0PlU"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # input layer\n",
        "    model.add(keras.layers.InputLayer(input_shape=(28, 28, 1)))\n",
        "\n",
        "    # first convolution layer\n",
        "    model.add(keras.layers.Conv2D(32, (5, 5), padding='same', kernel_initializer='he_uniform'))\n",
        "    model.add(keras.layers.ReLU())\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # second convolution layer\n",
        "    model.add(keras.layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform'))\n",
        "    model.add(keras.layers.ReLU())\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # transition to fully connected layers\n",
        "    model.add(keras.layers.Flatten())\n",
        "\n",
        "    # first dense layer\n",
        "    model.add(keras.layers.Dense(64, kernel_initializer='he_uniform'))\n",
        "    model.add(keras.layers.ReLU())\n",
        "    model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "    # second dense layer\n",
        "    model.add(keras.layers.Dense(64, kernel_initializer='he_uniform'))\n",
        "    model.add(keras.layers.ReLU())\n",
        "    model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "    # output layer\n",
        "    model.add(keras.layers.Dense(4, kernel_initializer='he_uniform', activation='sigmoid'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBHzhF3W0pQB"
      },
      "outputs": [],
      "source": [
        "# create a model\n",
        "model = get_model()\n",
        "print(model.summary())\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "    metrics='accuracy'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for file in os.listdir('Checkpoints'):\n",
        "    os.remove(f'Checkpoints/{file}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='Checkpoints/{epoch:02d}-{val_loss:.2f}.hdf5',\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czZby5tq5kYH"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset, epochs=100, validation_data=test_dataset, callbacks=[model_checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLEhpsco79gj",
        "outputId": "70197a24-12c1-4ef0-a4f7-8c38976fb506"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(test_dataset) < 0.5\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1LgB-CM-6rB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
