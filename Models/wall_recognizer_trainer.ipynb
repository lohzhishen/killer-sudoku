{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3l_-8tvxz23_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\lohzh\\Desktop\\Killer sudoku\\killer-sudoku\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import os\n",
        "\n",
        "MODEL = pathlib.Path('wall_recognizer.keras')\n",
        "LABELLED = pathlib.Path('Dataset', 'Wall Recognizer', 'Labelled')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2wiR-Oaw0p-o"
      },
      "outputs": [],
      "source": [
        "BUFFER = 128\n",
        "\n",
        "file_paths = tf.data.Dataset.list_files(str(LABELLED/'*.png'), shuffle=False).shuffle(BUFFER, reshuffle_each_iteration=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kotssfuh1XDo"
      },
      "outputs": [],
      "source": [
        "def parse_images(file_path):\n",
        "    # extract label\n",
        "    label = tf.strings.split(file_path, os.path.sep)[-1]\n",
        "    label = tf.strings.split(label, '_')[:-1]\n",
        "    label = tf.strings.to_number(label, tf.int32)\n",
        "\n",
        "    # load image\n",
        "    image = tf.io.read_file(file_path)\n",
        "    image = tf.io.decode_png(image, channels=1)\n",
        "    image = tf.image.resize(image, [28, 28])\n",
        "    image = tf.cast(image, tf.float32) / 255\n",
        "    return image, label\n",
        "\n",
        "dataset = file_paths.map(parse_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "L5ENpKce4qX1"
      },
      "outputs": [],
      "source": [
        "train_size = 800\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "test_dataset = dataset.skip(train_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olRCDr1q6BLo",
        "outputId": "d92f2051-0c73-4110-c7c0-fdf49a662132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "image = iter(train_dataset).__next__()\n",
        "print(image[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "bQnrU_yf5HlG",
        "outputId": "637f837d-e285-422f-99d1-3c477d05db56"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "for i, (image, label) in zip(range(3), iter(train_dataset)):\n",
        "    label = label.numpy().astype(np.uint8).tolist()\n",
        "\n",
        "    plt.subplot(1, 3, i + 1)\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.title('_'.join([str(x) for x in label]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "djm8qV5h8iBW"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.batch(1)\n",
        "test_dataset = test_dataset.batch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "EbPuuM0k0PlU"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # input layer\n",
        "    model.add(keras.layers.InputLayer(input_shape=(28, 28, 1)))\n",
        "\n",
        "    # first convolution layer\n",
        "    model.add(keras.layers.Conv2D(32, (5, 5), padding='same', kernel_initializer='he_uniform'))\n",
        "    model.add(keras.layers.ReLU())\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # second convolution layer\n",
        "    model.add(keras.layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform'))\n",
        "    model.add(keras.layers.ReLU())\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # transition to fully connected layers\n",
        "    model.add(keras.layers.Flatten())\n",
        "\n",
        "    # first dense layer\n",
        "    model.add(keras.layers.Dense(64, kernel_initializer='he_uniform'))\n",
        "    model.add(keras.layers.ReLU())\n",
        "    model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "    # second dense layer\n",
        "    model.add(keras.layers.Dense(64, kernel_initializer='he_uniform'))\n",
        "    model.add(keras.layers.ReLU())\n",
        "    model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "    # output layer\n",
        "    model.add(keras.layers.Dense(4, kernel_initializer='he_uniform', activation='sigmoid'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "BBHzhF3W0pQB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 32)        832       \n",
            "                                                                 \n",
            " re_lu_4 (ReLU)              (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 14, 14, 32)        9248      \n",
            "                                                                 \n",
            " re_lu_5 (ReLU)              (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1568)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                100416    \n",
            "                                                                 \n",
            " re_lu_6 (ReLU)              (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " re_lu_7 (ReLU)              (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114916 (448.89 KB)\n",
            "Trainable params: 114916 (448.89 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# create a model\n",
        "model = get_model()\n",
        "print(model.summary())\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "    metrics='accuracy'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "for file in os.listdir('Checkpoints'):\n",
        "    os.remove(f'Checkpoints/{file}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='Checkpoints/{epoch:02d}-{val_loss:.2f}.hdf5',\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "czZby5tq5kYH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "800/800 [==============================] - 5s 4ms/step - loss: 0.5334 - accuracy: 0.3438 - val_loss: 0.4064 - val_accuracy: 0.9843\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3882 - accuracy: 0.3762 - val_loss: 0.2516 - val_accuracy: 0.7677\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2853 - accuracy: 0.3913 - val_loss: 0.2244 - val_accuracy: 0.5669\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2545 - accuracy: 0.4238 - val_loss: 0.1696 - val_accuracy: 0.5394\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2256 - accuracy: 0.3875 - val_loss: 0.1672 - val_accuracy: 0.3465\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1911 - accuracy: 0.3825 - val_loss: 0.1368 - val_accuracy: 0.4449\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1628 - accuracy: 0.4125 - val_loss: 0.0842 - val_accuracy: 0.4724\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1460 - accuracy: 0.3787 - val_loss: 0.1087 - val_accuracy: 0.1614\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1374 - accuracy: 0.3587 - val_loss: 0.0832 - val_accuracy: 0.1220\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1060 - accuracy: 0.3963 - val_loss: 0.0708 - val_accuracy: 0.5472\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1003 - accuracy: 0.3375 - val_loss: 0.0864 - val_accuracy: 0.0827\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1007 - accuracy: 0.3625 - val_loss: 0.0757 - val_accuracy: 0.1575\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0959 - accuracy: 0.3512 - val_loss: 0.0722 - val_accuracy: 0.6969\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0914 - accuracy: 0.3675 - val_loss: 0.0827 - val_accuracy: 0.0551\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0848 - accuracy: 0.3512 - val_loss: 0.0478 - val_accuracy: 0.0945\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0849 - accuracy: 0.3625 - val_loss: 0.1058 - val_accuracy: 0.1063\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0795 - accuracy: 0.4150 - val_loss: 0.0853 - val_accuracy: 0.2165\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0743 - accuracy: 0.3388 - val_loss: 0.1031 - val_accuracy: 0.1535\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0685 - accuracy: 0.3688 - val_loss: 0.0689 - val_accuracy: 0.0827\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0815 - accuracy: 0.4075 - val_loss: 0.0519 - val_accuracy: 0.0591\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0669 - accuracy: 0.3338 - val_loss: 0.0898 - val_accuracy: 0.0472\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0582 - accuracy: 0.3325 - val_loss: 0.0676 - val_accuracy: 0.1142\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0634 - accuracy: 0.3700 - val_loss: 0.0880 - val_accuracy: 0.0945\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0520 - accuracy: 0.3725 - val_loss: 0.0426 - val_accuracy: 0.0433\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0531 - accuracy: 0.3550 - val_loss: 0.0503 - val_accuracy: 0.1181\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0492 - accuracy: 0.3812 - val_loss: 0.0702 - val_accuracy: 0.0315\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0525 - accuracy: 0.3450 - val_loss: 0.0563 - val_accuracy: 0.1457\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0554 - accuracy: 0.3475 - val_loss: 0.0793 - val_accuracy: 0.0630\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0486 - accuracy: 0.3537 - val_loss: 0.0591 - val_accuracy: 0.0787\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0526 - accuracy: 0.3413 - val_loss: 0.0307 - val_accuracy: 0.0039\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0462 - accuracy: 0.3875 - val_loss: 0.0262 - val_accuracy: 0.1732\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0397 - accuracy: 0.3512 - val_loss: 0.0528 - val_accuracy: 0.0472\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0492 - accuracy: 0.3738 - val_loss: 0.0216 - val_accuracy: 0.0276\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0423 - accuracy: 0.3600 - val_loss: 0.0667 - val_accuracy: 0.0315\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0427 - accuracy: 0.3512 - val_loss: 0.0603 - val_accuracy: 0.0276\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0410 - accuracy: 0.3537 - val_loss: 0.0614 - val_accuracy: 0.1496\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0429 - accuracy: 0.3250 - val_loss: 0.0539 - val_accuracy: 0.0236\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0413 - accuracy: 0.3350 - val_loss: 0.0493 - val_accuracy: 0.0551\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0446 - accuracy: 0.3313 - val_loss: 0.0552 - val_accuracy: 0.1102\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0490 - accuracy: 0.3250 - val_loss: 0.0642 - val_accuracy: 0.0472\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0314 - accuracy: 0.3738 - val_loss: 0.0415 - val_accuracy: 0.1693\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0376 - accuracy: 0.3800 - val_loss: 0.0696 - val_accuracy: 0.6575\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0364 - accuracy: 0.3787 - val_loss: 0.0329 - val_accuracy: 0.1811\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0312 - accuracy: 0.3862 - val_loss: 0.0632 - val_accuracy: 0.1102\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0405 - accuracy: 0.3288 - val_loss: 0.0345 - val_accuracy: 0.0039\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0349 - accuracy: 0.3212 - val_loss: 0.0637 - val_accuracy: 0.0276\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0315 - accuracy: 0.3787 - val_loss: 0.0249 - val_accuracy: 0.0236\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0332 - accuracy: 0.3587 - val_loss: 0.0381 - val_accuracy: 0.0472\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0359 - accuracy: 0.3575 - val_loss: 0.0337 - val_accuracy: 0.0276\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.4075 - val_loss: 0.0263 - val_accuracy: 0.0354\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0322 - accuracy: 0.3650 - val_loss: 0.0503 - val_accuracy: 0.0118\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0281 - accuracy: 0.3425 - val_loss: 0.0608 - val_accuracy: 0.0157\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0311 - accuracy: 0.4062 - val_loss: 0.0461 - val_accuracy: 0.0827\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0268 - accuracy: 0.4212 - val_loss: 0.0254 - val_accuracy: 0.1024\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0290 - accuracy: 0.3850 - val_loss: 0.0450 - val_accuracy: 0.2283\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0318 - accuracy: 0.4150 - val_loss: 0.0255 - val_accuracy: 0.1496\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0332 - accuracy: 0.3625 - val_loss: 0.0374 - val_accuracy: 0.0551\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 4s 6ms/step - loss: 0.0310 - accuracy: 0.3625 - val_loss: 0.0349 - val_accuracy: 0.0866\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0227 - accuracy: 0.3875 - val_loss: 0.0115 - val_accuracy: 0.0551\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0298 - accuracy: 0.3525 - val_loss: 0.0158 - val_accuracy: 0.0039\n",
            "Epoch 61/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0321 - accuracy: 0.3413 - val_loss: 0.0114 - val_accuracy: 0.0079\n",
            "Epoch 62/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0300 - accuracy: 0.3975 - val_loss: 0.0240 - val_accuracy: 0.0354\n",
            "Epoch 63/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0277 - accuracy: 0.4125 - val_loss: 0.0266 - val_accuracy: 0.0512\n",
            "Epoch 64/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0296 - accuracy: 0.4238 - val_loss: 0.0552 - val_accuracy: 0.0433\n",
            "Epoch 65/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0223 - accuracy: 0.4225 - val_loss: 0.0176 - val_accuracy: 0.0906\n",
            "Epoch 66/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0246 - accuracy: 0.3713 - val_loss: 0.0440 - val_accuracy: 0.0039\n",
            "Epoch 67/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0245 - accuracy: 0.3812 - val_loss: 0.0087 - val_accuracy: 0.0276\n",
            "Epoch 68/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0203 - accuracy: 0.3925 - val_loss: 0.0444 - val_accuracy: 0.1654\n",
            "Epoch 69/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0215 - accuracy: 0.4200 - val_loss: 0.0538 - val_accuracy: 0.0315\n",
            "Epoch 70/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0273 - accuracy: 0.4150 - val_loss: 0.0442 - val_accuracy: 0.1024\n",
            "Epoch 71/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0289 - accuracy: 0.3700 - val_loss: 0.0222 - val_accuracy: 0.0315\n",
            "Epoch 72/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0193 - accuracy: 0.3925 - val_loss: 0.0280 - val_accuracy: 0.0079\n",
            "Epoch 73/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0173 - accuracy: 0.3462 - val_loss: 0.0321 - val_accuracy: 0.0079\n",
            "Epoch 74/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0260 - accuracy: 0.3750 - val_loss: 0.0765 - val_accuracy: 0.0276\n",
            "Epoch 75/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0224 - accuracy: 0.3875 - val_loss: 0.0638 - val_accuracy: 0.0197\n",
            "Epoch 76/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0320 - accuracy: 0.3388 - val_loss: 0.0700 - val_accuracy: 0.0236\n",
            "Epoch 77/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0202 - accuracy: 0.3800 - val_loss: 0.0458 - val_accuracy: 0.0079\n",
            "Epoch 78/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0221 - accuracy: 0.4013 - val_loss: 0.0428 - val_accuracy: 0.0039\n",
            "Epoch 79/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0170 - accuracy: 0.4175 - val_loss: 0.0046 - val_accuracy: 0.1378\n",
            "Epoch 80/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0190 - accuracy: 0.4112 - val_loss: 0.0140 - val_accuracy: 0.0394\n",
            "Epoch 81/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0237 - accuracy: 0.3587 - val_loss: 0.0692 - val_accuracy: 0.0472\n",
            "Epoch 82/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0164 - accuracy: 0.3625 - val_loss: 0.0715 - val_accuracy: 0.0079\n",
            "Epoch 83/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0245 - accuracy: 0.4162 - val_loss: 0.0205 - val_accuracy: 0.0039\n",
            "Epoch 84/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0239 - accuracy: 0.3775 - val_loss: 0.0179 - val_accuracy: 0.0157\n",
            "Epoch 85/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0178 - accuracy: 0.3925 - val_loss: 0.0207 - val_accuracy: 0.0079\n",
            "Epoch 86/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0140 - accuracy: 0.3600 - val_loss: 0.0371 - val_accuracy: 0.0827\n",
            "Epoch 87/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0225 - accuracy: 0.3787 - val_loss: 0.0303 - val_accuracy: 0.0315\n",
            "Epoch 88/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0169 - accuracy: 0.3725 - val_loss: 0.0121 - val_accuracy: 0.0394\n",
            "Epoch 89/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0193 - accuracy: 0.3925 - val_loss: 0.0154 - val_accuracy: 0.0197\n",
            "Epoch 90/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0250 - accuracy: 0.3738 - val_loss: 0.0233 - val_accuracy: 0.0079\n",
            "Epoch 91/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0262 - accuracy: 0.3775 - val_loss: 0.0252 - val_accuracy: 0.0118\n",
            "Epoch 92/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0150 - accuracy: 0.4187 - val_loss: 0.0191 - val_accuracy: 0.0197\n",
            "Epoch 93/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0170 - accuracy: 0.3738 - val_loss: 0.0223 - val_accuracy: 0.0157\n",
            "Epoch 94/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0214 - accuracy: 0.4038 - val_loss: 0.0113 - val_accuracy: 0.0039\n",
            "Epoch 95/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0222 - accuracy: 0.3638 - val_loss: 0.0155 - val_accuracy: 0.0039\n",
            "Epoch 96/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0172 - accuracy: 0.3487 - val_loss: 0.0403 - val_accuracy: 0.0039\n",
            "Epoch 97/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0252 - accuracy: 0.3850 - val_loss: 0.0493 - val_accuracy: 0.0315\n",
            "Epoch 98/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0171 - accuracy: 0.3650 - val_loss: 0.0415 - val_accuracy: 0.0236\n",
            "Epoch 99/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0183 - accuracy: 0.3587 - val_loss: 0.0356 - val_accuracy: 0.0472\n",
            "Epoch 100/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.0176 - accuracy: 0.3812 - val_loss: 0.0260 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_dataset, epochs=100, validation_data=test_dataset, callbacks=[model_checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "254/254 [==============================] - 1s 2ms/step - loss: 0.0260 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.026007825508713722, 0.0]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLEhpsco79gj",
        "outputId": "70197a24-12c1-4ef0-a4f7-8c38976fb506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "254/254 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(False, False, True, False)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = (model.predict(test_dataset) < 0.5)[0]\n",
        "tuple(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1LgB-CM-6rB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
